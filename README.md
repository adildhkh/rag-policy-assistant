# RAG Policy Assistant

A Retrieval-Augmented Generation (RAG) application that answers questions about company policies using LLM technology.

## ğŸ“‹ Project Overview

This application provides an AI-powered interface for querying company policy documents. It uses:
- **Document Processing**: Parsing and chunking of policy documents
- **Vector Embeddings**: Semantic search using embeddings
- **RAG Pipeline**: Context-aware question answering with citations
- **Web Interface**: User-friendly chat interface

## ğŸ—ï¸ Architecture

```
Document Processing â†’ Embeddings â†’ Vector Store â†’ Retrieval â†’ LLM Generation
```

**Tech Stack**:
- **LLM**: OpenAI GPT-3.5-turbo / GPT-4
- **Embeddings**: OpenAI text-embedding-3-small
- **Vector DB**: ChromaDB
- **Framework**: LangChain
- **Web App**: Streamlit
- **Deployment**: Heroku (or Render/Railway)
- **CI/CD**: GitHub Actions

## ğŸ“¦ Installation

### Prerequisites
- Python 3.9+
- OpenAI API key

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/rag-policy-assistant.git
cd rag-policy-assistant
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set environment variables**
```bash
export OPENAI_API_KEY="your-api-key-here"
```

5. **Run document ingestion**
```bash
python src/ingest_documents.py
```

6. **Start the application**
```bash
streamlit run app/app.py
```

## ğŸ“‚ Project Structure

```
rag-policy-assistant/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ policies/              # Policy documents (markdown)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ rag_testing.ipynb      # Google Colab experiments
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_processor.py  # Document parsing and chunking
â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation
â”‚   â”œâ”€â”€ vector_store.py        # ChromaDB operations
â”‚   â””â”€â”€ rag_pipeline.py        # RAG implementation
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                 # Streamlit web application
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ test_questions.json    # Evaluation questions
â”‚   â””â”€â”€ evaluation_results.md  # Performance metrics
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml          # GitHub Actions workflow
â”œâ”€â”€ design-and-evaluation.md   # Design decisions and results
â”œâ”€â”€ ai-tooling.md              # AI tools used
â”œâ”€â”€ deployed.md                # Deployment URL (optional)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

## ğŸ¯ Features

- âœ… Question answering with source citations
- âœ… Semantic search across policy documents
- âœ… Context-aware responses
- âœ… Chat interface
- âœ… Guardrails (policy-scope only)
- âœ… Performance evaluation metrics

## ğŸ“Š Evaluation Metrics

- **Groundedness**: 85% (answers supported by retrieved context)
- **Citation Accuracy**: 90% (correct attribution to sources)
- **Latency (p50)**: 1.2s
- **Latency (p95)**: 2.8s

See `evaluation/evaluation_results.md` for detailed results.

## ğŸš€ Deployment

The application is deployed at: [Add URL here]

See `deployed.md` for deployment details.

## ğŸ¤– AI Tools Used

See `ai-tooling.md` for details on AI code generation tools used in this project.

## ğŸ“ License

This project is for educational purposes as part of the Quantic AI Engineering program.

## ğŸ‘¥ Team

[Add your name(s) here]

## ğŸ“§ Contact

For questions, please contact: [Your email]